{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bayesian_search.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1KdmFc9CjZe9wYE_OuUNo3z0BvapOdPNZ",
      "authorship_tag": "ABX9TyORvxd0UQEZQiO1z5wvVfmO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mankicom/DEV_GDPS_TEMP_LSTM/blob/master/Bayesian_search.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bayesian optimization을 이용한 TCN 초모수 최적화**\n",
        "단기 풍속 편차보정모델 개발 예제\n",
        "\n"
      ],
      "metadata": {
        "id": "uL_Eoe-0Rs9g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **모듈로드**\n",
        "\n",
        "\n",
        "*   기본모듈: numpy, pandas, os, sys, time, joblib,f90nml\n",
        "> f90nml: 포트란 네임리스트 읽기 모듈\n",
        "*   Scikit-learn 및 Scikit-optimize\n",
        "> 입력자료 정규화, 교차검증, 초모수 최적화 관련 모듈\n",
        "*   Tensorflow, Keras, TCN 관련\n",
        "> 모델 개발 관련, Keras는 최근에 Tensorflow에 많은 기능이 포함되어 나옴\n",
        "*   Local 함수\n",
        "> 사용자 함수, 훈련자료 로드, 개량한 교차검증 함수\n",
        "\n",
        "특별히 설치해줘야할 모듈들\n",
        "> pip install f90nml\n",
        "\n",
        "> pip install scikit-optimize\n",
        "\n",
        "> pip install keras-tcn\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "icJ2ynsfSEaP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------------------------------------------------------------\n",
        "# .. Module load\n",
        "\n",
        "#.. module\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import sys\n",
        "from time import time\n",
        "#import joblib\n",
        "#import argparse\n",
        "import f90nml\n",
        "\n",
        "from sklearn.metrics import make_scorer, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "\n",
        "from tensorflow.compat.v1.keras.backend import set_session\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
        "from tensorflow.keras.models import model_from_json\n",
        "from tensorflow.keras.layers import Dense, TimeDistributed\n",
        "from tensorflow.keras import Input, Model, callbacks\n",
        "from tensorflow.keras.utils import plot_model as plm\n",
        "from tcn import TCN, tcn_full_summary\n",
        "from tensorflow.keras.activations import swish\n",
        "\n",
        "\n",
        "#.. local\n",
        "sys.path.insert(0, '/content/drive/MyDrive/BICR_DEEP_TEST/BAYES_OPT/SPD/inc')\n",
        "#from tran_data_split import tran_data_split\n",
        "from tran_data_load import tran_data_load\n",
        "from kmk_make_scorer import r2_3dim, mse_3dim, mae_3dim"
      ],
      "metadata": {
        "id": "QWdun_yrR84U"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **GPU 관련 디바이스 설정**\n",
        "\n",
        "\n",
        "*   Tensorflow 라이브러리 기반의 딥러닝 기법은 메모리 부족현상을 피하기 위해 처음부터 GPU의 사용가능 메모리를 최대로 잡는 설정이 있음. 이로인해 GPU 서버에서 다양한 작업이 불가해짐. 다음 설정을 통해 작업에 필요한 만큼만 메모리를 잡아줌\n",
        "\n"
      ],
      "metadata": {
        "id": "6HF7_f4lSH8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------------------------------------------------------------\n",
        "# .. Device configuration\n",
        "\n",
        "\n",
        "config = tf.compat.v1.ConfigProto()\n",
        "config.gpu_options.allow_growth = True\n",
        "set_session(tf.compat.v1.Session(config=config))\n"
      ],
      "metadata": {
        "id": "nxypa7qgSIjy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **변수설정**\n",
        "*   사용파일 관련 변수 설정\n",
        "*   TCN 초모수 설정\n",
        "*   초모수 최적화 탐색 조합 개수 설정\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2EP4_OrcSNWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------------------------------------------------------------\n",
        "# .. Data set\n",
        "\n",
        "element = 'ALLV'\n",
        "name_list = \"/content/drive/MyDrive/BICR_DEEP_TEST/BAYES_OPT/SPD/SHEL/namelist.input\"\n",
        "\n",
        "hp_lr = 0.009\n",
        "hp_pd = 'same'\n",
        "hp_ns = 1\n",
        "hp_dl = [1,2,4,8,17,34,68,136]\n",
        "hp_ldl = hp_dl[-1] # last dilation factor to make name of save model\n",
        "hp_bn = True\n",
        "n_iter_search = 2   #테스트 실행을 위해 작은수 설정\n",
        "\n"
      ],
      "metadata": {
        "id": "kGsPP9V_SQR-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **네임리스트 정보 호출**"
      ],
      "metadata": {
        "id": "T0ZkenyKSRYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------------------------------------------------------------\n",
        "# .. Read namelist\n",
        "\n",
        "print (\"1. Read namelist\")\n",
        "exists = os.path.isfile(name_list)\n",
        "if exists:\n",
        "    nml = f90nml.read(name_list)\n",
        "    tran_data_per = nml['data_set']['tran_data_per']\n",
        "    tran_num_his = nml['data_set']['tran_num_his']\n",
        "    test_data_per = nml['data_set']['test_data_per']\n",
        "    test_num_his = nml['data_set']['test_num_his']\n",
        "    num_fct = nml['data_set']['num_fct']\n",
        "    dev_stn_id = nml['data_set']['dev_stn_id']\n",
        "    exp_name = nml['data_set']['exp_name']\n",
        "    data_dir = nml['data_set']['data_dir']\n",
        "    input_size = nml['data_set']['input_size']\n",
        "    output_size = nml['data_set']['output_size']\n",
        "    num_epoch = nml['hyper_para']['num_epoch']\n",
        "    patience = nml['hyper_para']['patience']\n",
        "    hp_nf = nml['hyper_para']['n_filter']\n",
        "    hp_ks = nml['hyper_para']['s_kernel']\n",
        "    hp_dr = nml['hyper_para']['drp_rate']\n",
        "else:\n",
        "    sys.exit(\"STOP Error: Could not found : \"+ name_list)\n",
        "\n",
        "print(nml)\n",
        "\n",
        "#data_dir = './DAIN_MIX/'\n",
        "#data_dir = './DAIN_HR136/'\n",
        "data_dir = '/content/drive/MyDrive/BICR_DEEP_TEST/BAYES_OPT/SPD/DAIN/'\n",
        "num_epoch = 2 # 테스트 수행을 위해 작은수 설정\n",
        "\n",
        "# 출력자료 경로 설정\n",
        "csv_outdir = '/content/drive/MyDrive/BICR_DEEP_TEST/BAYES_OPT/SPD/DAOU/LOSS/' + exp_name + '/'\n",
        "model_outdir = '/content/drive/MyDrive/BICR_DEEP_TEST/BAYES_OPT/SPD/DAOU/MODL/' + exp_name + '/'\n",
        "scalr_outdir = '/content/drive/MyDrive/BICR_DEEP_TEST/BAYES_OPT/SPD/DAOU/SCAL/' + exp_name + '/'\n",
        "gifd_outdir = '/content/drive/MyDrive/BICR_DEEP_TEST/BAYES_OPT/SPD/GIFD/' + exp_name + '/'\n",
        "\n"
      ],
      "metadata": {
        "id": "hdVvrp-dSSng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5271180d-8247-482b-d6f0-d5620c0edd6f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Read namelist\n",
            "&data_set\n",
            "    tran_data_per = '2016050100-2021043000-24-1605-2104'\n",
            "    tran_num_his = 1826\n",
            "    test_data_per = '2021050100-2021092100-24-2105-2109'\n",
            "    test_num_his = 144\n",
            "    num_fct = 136\n",
            "    dev_stn_id = 47003\n",
            "    exp_name = 'OP_12UTC'\n",
            "    data_dir = '/home/mankicom/STD_POOL/SHRT_GDPS/HOURLY1/MODL_DVLP/SPD/TEST/DAIN/'\n",
            "    input_size = 10\n",
            "    output_size = 1\n",
            "/\n",
            "\n",
            "&hyper_para\n",
            "    num_epoch = 1000\n",
            "    patience = 1000\n",
            "    n_filter = 87\n",
            "    s_kernel = 6\n",
            "    drp_rate = 0.07\n",
            "/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **TCN 입력자료 호출**\n",
        "\n",
        "*   군집분석을 통해 선정된 대표지점 훈련자료 로드\n",
        "*   for 문을 통해 대표 지점개수만큼 로드한 후 한 변수에 표본개수를 병합\n",
        "\n"
      ],
      "metadata": {
        "id": "Y2Av41tiSWm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------------------------------------------------------------\n",
        "# .. Fcst load :  data dim( input_size, num_stn, num_his, num_fct )\n",
        "#\n",
        "#    Trainining data used for cross-validation\n",
        "#    Test data used to evaluate best model out of randomized search\n",
        "#\n",
        "\n",
        "print (\"3. Training/valid data load, combine 4stn(47169, 47133, 47102, 47090) train sample\")\n",
        "#tran_rate = 0.8\n",
        "eval_rate = 0.2\n",
        "#rd_seed_fix = False\n",
        "#nbin = 10\n",
        "\n",
        "#combine_stn = [47169, 47133, 47102, 47090]\n",
        "combine_stn = [47108, 47108, 47108, 47108]\n",
        "for i in range(len(combine_stn)):\n",
        "    tran_xx, tran_yy = tran_data_load(data_dir, tran_data_per,\n",
        "                                     element, input_size, output_size, tran_num_his,\n",
        "                                     num_fct, combine_stn[i])\n",
        "\n",
        "    if i == 0:\n",
        "       tran_x, tran_y = tran_xx, tran_yy\n",
        "    else:\n",
        "       tran_x = np.concatenate((tran_x,tran_xx), axis=1)\n",
        "       tran_y = np.concatenate((tran_y,tran_yy), axis=1)\n",
        "\n",
        "tran_x = np.swapaxes(tran_x,0,1)\n",
        "tran_y = np.swapaxes(tran_y,0,1)\n",
        "\n",
        "#-------------------------------------------------------------------------\n",
        "# .. Check diemsion\n",
        "\n",
        "input_size = tran_x.shape[2]\n",
        "output_size = tran_y.shape[2]\n",
        "print (\"5. Select var\")\n",
        "print ('tran_x shape= ', tran_x.shape)    # batch, sequence, feature\n",
        "print ('tran_y shape= ', tran_y.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "sinGzxOgSXia",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42222b3a-e074-4fdb-9b22-11f4af1472d7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3. Training/valid data load, combine 4stn(47169, 47133, 47102, 47090) train sample\n",
            "Read input:  /content/drive/MyDrive/BICR_DEEP_TEST/BAYES_OPT/SPD/DAIN/OBS/tran_obs_spd.2016050100-2021043000-24-1605-2104_47108\n",
            "FILE date:  [2016    5    1    0] [2021    4   30    0] [24]\n",
            "READ  DIMENSION: NV =  1\n",
            "READ  DIMENSION: NS =  1\n",
            "READ  DIMENSION: NH =  1826\n",
            "READ  DIMENSION: NF =  136\n",
            "USER Request dimension: \n",
            "USER  DIMENSION: NV =  1\n",
            "USER  DIMENSION: NS =  1\n",
            "USER  DIMENSION: NH =  1826\n",
            "USER  DIMENSION: NF =  136\n",
            "Read input:  /content/drive/MyDrive/BICR_DEEP_TEST/BAYES_OPT/SPD/DAIN/NWP/LC/tran_gmix_ALLV_nvar10.2016050100-2021043000-24-1605-2104_47108\n",
            "FILE date:  [2016    5    1    0] [2021    4   30    0] [24]\n",
            "READ  DIMENSION: NV =  10\n",
            "READ  DIMENSION: NS =  1\n",
            "READ  DIMENSION: NH =  1826\n",
            "READ  DIMENSION: NF =  136\n",
            "USER Request dimension: \n",
            "USER  DIMENSION: NV =  10\n",
            "USER  DIMENSION: NS =  1\n",
            "USER  DIMENSION: NH =  1826\n",
            "USER  DIMENSION: NF =  136\n",
            "Read obs raw dimension: \n",
            "Read nwp raw dimension: \n",
            "---------- Reshape for lstm input dimension\n",
            "reshape_nwp_stn  (136, 1826, 10)\n",
            "reshape_obs_stn  (136, 1826, 1)\n",
            "---------- In remove nan batch\n",
            "nwp  (136, 1826, 10)\n",
            "obs  (136, 1826, 1)\n",
            "missing count =  59\n",
            "missing days =  [248 248 248 ... 254 254 254]\n",
            "Remove nan (array([  0,   0,   0, ..., 135, 135, 135]), array([248, 248, 248, ..., 254, 254, 254]), array([0, 1, 2, ..., 7, 8, 9]))\n",
            "---------- Shape of after drop nan \n",
            "(136, 1767, 10)\n",
            "(136, 1767, 1)\n",
            "Read input:  /content/drive/MyDrive/BICR_DEEP_TEST/BAYES_OPT/SPD/DAIN/OBS/tran_obs_spd.2016050100-2021043000-24-1605-2104_47108\n",
            "FILE date:  [2016    5    1    0] [2021    4   30    0] [24]\n",
            "READ  DIMENSION: NV =  1\n",
            "READ  DIMENSION: NS =  1\n",
            "READ  DIMENSION: NH =  1826\n",
            "READ  DIMENSION: NF =  136\n",
            "USER Request dimension: \n",
            "USER  DIMENSION: NV =  1\n",
            "USER  DIMENSION: NS =  1\n",
            "USER  DIMENSION: NH =  1826\n",
            "USER  DIMENSION: NF =  136\n",
            "Read input:  /content/drive/MyDrive/BICR_DEEP_TEST/BAYES_OPT/SPD/DAIN/NWP/LC/tran_gmix_ALLV_nvar10.2016050100-2021043000-24-1605-2104_47108\n",
            "FILE date:  [2016    5    1    0] [2021    4   30    0] [24]\n",
            "READ  DIMENSION: NV =  10\n",
            "READ  DIMENSION: NS =  1\n",
            "READ  DIMENSION: NH =  1826\n",
            "READ  DIMENSION: NF =  136\n",
            "USER Request dimension: \n",
            "USER  DIMENSION: NV =  10\n",
            "USER  DIMENSION: NS =  1\n",
            "USER  DIMENSION: NH =  1826\n",
            "USER  DIMENSION: NF =  136\n",
            "Read obs raw dimension: \n",
            "Read nwp raw dimension: \n",
            "---------- Reshape for lstm input dimension\n",
            "reshape_nwp_stn  (136, 1826, 10)\n",
            "reshape_obs_stn  (136, 1826, 1)\n",
            "---------- In remove nan batch\n",
            "nwp  (136, 1826, 10)\n",
            "obs  (136, 1826, 1)\n",
            "missing count =  59\n",
            "missing days =  [248 248 248 ... 254 254 254]\n",
            "Remove nan (array([  0,   0,   0, ..., 135, 135, 135]), array([248, 248, 248, ..., 254, 254, 254]), array([0, 1, 2, ..., 7, 8, 9]))\n",
            "---------- Shape of after drop nan \n",
            "(136, 1767, 10)\n",
            "(136, 1767, 1)\n",
            "Read input:  /content/drive/MyDrive/BICR_DEEP_TEST/BAYES_OPT/SPD/DAIN/OBS/tran_obs_spd.2016050100-2021043000-24-1605-2104_47108\n",
            "FILE date:  [2016    5    1    0] [2021    4   30    0] [24]\n",
            "READ  DIMENSION: NV =  1\n",
            "READ  DIMENSION: NS =  1\n",
            "READ  DIMENSION: NH =  1826\n",
            "READ  DIMENSION: NF =  136\n",
            "USER Request dimension: \n",
            "USER  DIMENSION: NV =  1\n",
            "USER  DIMENSION: NS =  1\n",
            "USER  DIMENSION: NH =  1826\n",
            "USER  DIMENSION: NF =  136\n",
            "Read input:  /content/drive/MyDrive/BICR_DEEP_TEST/BAYES_OPT/SPD/DAIN/NWP/LC/tran_gmix_ALLV_nvar10.2016050100-2021043000-24-1605-2104_47108\n",
            "FILE date:  [2016    5    1    0] [2021    4   30    0] [24]\n",
            "READ  DIMENSION: NV =  10\n",
            "READ  DIMENSION: NS =  1\n",
            "READ  DIMENSION: NH =  1826\n",
            "READ  DIMENSION: NF =  136\n",
            "USER Request dimension: \n",
            "USER  DIMENSION: NV =  10\n",
            "USER  DIMENSION: NS =  1\n",
            "USER  DIMENSION: NH =  1826\n",
            "USER  DIMENSION: NF =  136\n",
            "Read obs raw dimension: \n",
            "Read nwp raw dimension: \n",
            "---------- Reshape for lstm input dimension\n",
            "reshape_nwp_stn  (136, 1826, 10)\n",
            "reshape_obs_stn  (136, 1826, 1)\n",
            "---------- In remove nan batch\n",
            "nwp  (136, 1826, 10)\n",
            "obs  (136, 1826, 1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/drive/MyDrive/BICR_DEEP_TEST/BAYES_OPT/SPD/inc/test_read_fortranfile.py:37: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  stn_id = f.read_record( np.dtype((np.int32,(NS1))) )\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing count =  59\n",
            "missing days =  [248 248 248 ... 254 254 254]\n",
            "Remove nan (array([  0,   0,   0, ..., 135, 135, 135]), array([248, 248, 248, ..., 254, 254, 254]), array([0, 1, 2, ..., 7, 8, 9]))\n",
            "---------- Shape of after drop nan \n",
            "(136, 1767, 10)\n",
            "(136, 1767, 1)\n",
            "Read input:  /content/drive/MyDrive/BICR_DEEP_TEST/BAYES_OPT/SPD/DAIN/OBS/tran_obs_spd.2016050100-2021043000-24-1605-2104_47108\n",
            "FILE date:  [2016    5    1    0] [2021    4   30    0] [24]\n",
            "READ  DIMENSION: NV =  1\n",
            "READ  DIMENSION: NS =  1\n",
            "READ  DIMENSION: NH =  1826\n",
            "READ  DIMENSION: NF =  136\n",
            "USER Request dimension: \n",
            "USER  DIMENSION: NV =  1\n",
            "USER  DIMENSION: NS =  1\n",
            "USER  DIMENSION: NH =  1826\n",
            "USER  DIMENSION: NF =  136\n",
            "Read input:  /content/drive/MyDrive/BICR_DEEP_TEST/BAYES_OPT/SPD/DAIN/NWP/LC/tran_gmix_ALLV_nvar10.2016050100-2021043000-24-1605-2104_47108\n",
            "FILE date:  [2016    5    1    0] [2021    4   30    0] [24]\n",
            "READ  DIMENSION: NV =  10\n",
            "READ  DIMENSION: NS =  1\n",
            "READ  DIMENSION: NH =  1826\n",
            "READ  DIMENSION: NF =  136\n",
            "USER Request dimension: \n",
            "USER  DIMENSION: NV =  10\n",
            "USER  DIMENSION: NS =  1\n",
            "USER  DIMENSION: NH =  1826\n",
            "USER  DIMENSION: NF =  136\n",
            "Read obs raw dimension: \n",
            "Read nwp raw dimension: \n",
            "---------- Reshape for lstm input dimension\n",
            "reshape_nwp_stn  (136, 1826, 10)\n",
            "reshape_obs_stn  (136, 1826, 1)\n",
            "---------- In remove nan batch\n",
            "nwp  (136, 1826, 10)\n",
            "obs  (136, 1826, 1)\n",
            "missing count =  59\n",
            "missing days =  [248 248 248 ... 254 254 254]\n",
            "Remove nan (array([  0,   0,   0, ..., 135, 135, 135]), array([248, 248, 248, ..., 254, 254, 254]), array([0, 1, 2, ..., 7, 8, 9]))\n",
            "---------- Shape of after drop nan \n",
            "(136, 1767, 10)\n",
            "(136, 1767, 1)\n",
            "5. Select var\n",
            "tran_x shape=  (7068, 136, 10)\n",
            "tran_y shape=  (7068, 136, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **정규화**\n",
        "\n",
        "\n",
        "*   로드된 대표지점 병합 훈련자료를 정규화\n",
        "*   Scikit-learn의 MinMaxScaler 함수를 이용해 피팅 후 변환\n",
        "> scaler의 입력형태가 [batch, feature]를 요구하기 때문에 3차원 데이터를 2차원으로 변환후 스케일링 수행. 수행이 끝나면 다시 3차원으로 복원\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Usidzi02Sc_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------------------------------------------------------------\n",
        "# .. Normalize\n",
        "\n",
        "# .. initialaize\n",
        "tr_b, tr_s, tr_f = tran_x.shape[0], tran_x.shape[1], tran_x.shape[2]\n",
        "\n",
        "\n",
        "# .. get restorator with obs range\n",
        "nwp_scaler = MinMaxScaler()   # copy default true\n",
        "obs_scaler = MinMaxScaler()\n",
        "nwp_scaler.fit(tran_x.view().reshape(tr_b*tr_s, tr_f))\n",
        "obs_scaler.fit(tran_y.view().reshape(tr_b*tr_s, output_size))\n",
        "\n",
        "# .. feature normalize   ( train seq, feature = test seq, feature )\n",
        "nor_tran_x = nwp_scaler.transform(tran_x.reshape(tr_b*tr_s, tr_f))\n",
        "nor_tran_x = nor_tran_x.reshape(tr_b,tr_s,tr_f)\n",
        "nor_tran_y = obs_scaler.transform(tran_y.reshape(tr_b*tr_s, output_size))\n",
        "nor_tran_y = nor_tran_y.reshape(tr_b,tr_s, output_size)\n",
        "\n",
        "\n",
        "\n",
        "print ('---------- Final training data shape')\n",
        "print(type(nor_tran_x))\n",
        "print ('tran nwp : ', nor_tran_x.shape)\n",
        "print ('tran obs : ', nor_tran_y.shape)\n"
      ],
      "metadata": {
        "id": "tvoEuyKISf4T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69ab8d46-a81f-4283-e771-5720143518fa"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------- Final training data shape\n",
            "<class 'numpy.ndarray'>\n",
            "tran nwp :  (7068, 136, 10)\n",
            "tran obs :  (7068, 136, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **TCN모델 설정 및 초모수 최적화 설정**\n",
        "\n",
        "\n",
        "*   scikit-optimizer를 이용한 초모수 최적화를 위해 TCN 모델을 반환해주는 함수 정의(create_model(아규먼트에 최적화할 변수 사전정의))\n",
        "*   keras-tcn과 scikit-optimizer와의 호환을 위해 KerasRegressor 함수로 wrapping\n",
        "\n"
      ],
      "metadata": {
        "id": "ofabSskzShCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#=========================================================================\n",
        "# .. Model configuration\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------------\n",
        "# .. Set mini batch for cross-validation\n",
        "\n",
        "#num_cv=5\n",
        "num_cv=2 #테스트를 위해 작은수 설정\n",
        "batch_size = int( nor_tran_x.shape[0]*0.1 )\n",
        "\n",
        "\n",
        "print ('input_size: ', input_size)\n",
        "print ('batch_size: ', batch_size)\n",
        "print ('time_lenght: ', num_fct)\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------------\n",
        "# .. Set Model\n",
        "\n",
        "\n",
        "# .. Define model\n",
        "# 최적화할 변수들은 함수 아규먼트 칸에 사전 정의 해주세요\n",
        "def create_model(dropout_rate=0.15, nb_filters=7, kernel_size=3):\n",
        "\n",
        "          print ('================== Model called ========================')\n",
        "          print ('input_size: ', input_size)\n",
        "          print ('batch_size: ', batch_size)\n",
        "          print ('time_lenght: ', num_fct)\n",
        "          print ('nb_filters: ', nb_filters)\n",
        "          print ('kernel_size: ', kernel_size)\n",
        "          print ('dropout_rate: ', dropout_rate)\n",
        "          print ('dilations: ', hp_dl)\n",
        "          dropout_rate = np.round(dropout_rate,2)\n",
        "          print ('dropout_rate: ', dropout_rate)\n",
        "\n",
        "          ## .. clear keras model\n",
        "          K.clear_session()\n",
        "\n",
        "          # .. create model\n",
        "          #i = Input( batch_shape=(batch_size, num_fct, input_size) )\n",
        "          # batch=None 중요!!, 미니배치 크기를 훈련자료 개수의 %로 정의하기 때문에 \n",
        "          # 딱 나누어 떨어지지 않으면 일정값을 정의할 경우 에러발생 \n",
        "          i = Input( batch_shape=(None, num_fct, input_size) )\n",
        "          o = TCN(return_sequences=True,\n",
        "                  activation=swish,\n",
        "                  nb_filters=nb_filters,\n",
        "                  padding=hp_pd,\n",
        "                  use_batch_norm = hp_bn,\n",
        "                  nb_stacks=hp_ns,\n",
        "                  dropout_rate=dropout_rate,\n",
        "                  kernel_size=kernel_size,\n",
        "                  use_skip_connections=True,\n",
        "                  dilations=hp_dl\n",
        "                  )(i)\n",
        "          o = TimeDistributed(Dense(output_size, activation='linear'))(o)\n",
        "\n",
        "          # .. compile\n",
        "          adam = optimizers.Adam(lr=hp_lr)\n",
        "\n",
        "          m= Model(inputs=[i], outputs=[o])\n",
        "          m.compile(optimizer=adam, loss='mse')\n",
        "\n",
        "          m.summary()\n",
        "\n",
        "          return m\n",
        "\n",
        "\n",
        "# .. Wrapping create_model for scikit-optimizer form\n",
        "model = KerasRegressor(build_fn=create_model,\n",
        "                       verbose=1,\n",
        "                       epochs=num_epoch,\n",
        "                       batch_size=batch_size,\n",
        "                       shuffle=True)"
      ],
      "metadata": {
        "id": "wGsiZR-iSokh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48280f63-84ac-414b-bd12-9807720becfd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_size:  10\n",
            "batch_size:  706\n",
            "time_lenght:  136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:75: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **BayesSearchCV를 이용한 TCN 초모수 최적화**\n",
        "\n",
        "\n",
        "*   탐색할 초모수 및 범위 설정\n",
        "*   교차검증 스코어 설정\n",
        "*   optimizer 설정(=BayesSearchCV)\n",
        "*   최적화 결과출력(Best 조합 및 rank 별 조합)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4IfZLLB2SsV8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#-------------------------------------------------------------------------\n",
        "# .. Use bayes_opt\n",
        "\n",
        "# .. Exp para set\n",
        "#param_dist = { 'padding': Categorical(['causal','same']),\n",
        "#               'nb_stacks': Integer(1,5),\n",
        "#               'nb_filters': Categorical([7,20,30]),\n",
        "#               'kernel_size': Integer(2,24) }\n",
        "#param_dist = { 'dropout_rate': Real(0.01, 0.2),\n",
        "#               'nb_filters': Integer(50,100),\n",
        "#               'kernel_size': Integer(3,12) }\n",
        "##param_dist = { 'dropout_rate': Categorical([0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.15]),\n",
        "#               'nb_filters': Integer(50,100),\n",
        "#               'kernel_size': Integer(3,12) }\n",
        "param_dist = { 'nb_filters': Integer(50,100),\n",
        "               'kernel_size': Integer(3,12) }\n",
        "\n",
        "set_eval_score = { 'MAE': make_scorer(mae_3dim),\n",
        "                   'MSE': make_scorer(mse_3dim),\n",
        "                   'R2': make_scorer(r2_3dim) }\n",
        "\n",
        "print ( param_dist )\n",
        "\n",
        "optimizer =  BayesSearchCV( estimator=model,\n",
        "                            search_spaces=param_dist,\n",
        "                            scoring=make_scorer(r2_3dim),\n",
        "                            refit=False,\n",
        "                            cv=num_cv,\n",
        "                            n_iter=n_iter_search,\n",
        "                            return_train_score=True,\n",
        "                            verbose=1,\n",
        "                            n_jobs=1,\n",
        "                            random_state=1 )\n",
        "\n",
        "start = time()\n",
        "print(nor_tran_x.shape, nor_tran_y.shape)\n",
        "optimizer.fit(nor_tran_x, nor_tran_y)\n",
        "\n",
        "print(type(optimizer.cv_results_))\n",
        "print(optimizer.cv_results_)\n",
        "\n",
        "# .. Report\n",
        "def report(result, n_top=n_iter_search):\n",
        "    for i in range(n_top):\n",
        "        candidates = [ result['rank_test_score'][i] ]\n",
        "        for candidate in candidates:\n",
        "            print(\"Rank: %0d, R2: %.3f with %r\" %\n",
        "                  ( i, result['mean_test_score'][candidate-1],\n",
        "                       result['params'][candidate-1] ) )\n",
        "\n",
        "\n",
        "print(\"BayesSearchCV took %.2f seconds for %d candidates\"\n",
        "      \" parameter settings. \" % ((time() - start), n_iter_search))\n",
        "\n",
        "print( \"Best: %f using %s\" % ( optimizer.best_score_,\n",
        "                               optimizer.best_params_ ) )\n",
        "\n",
        "report(optimizer.cv_results_)"
      ],
      "metadata": {
        "id": "yxjPENFBStS5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf4ed35d-31a1-4d86-eadf-4b2d78bf27f8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'nb_filters': Integer(low=50, high=100, prior='uniform', transform='identity'), 'kernel_size': Integer(low=3, high=12, prior='uniform', transform='identity')}\n",
            "(7068, 136, 10) (7068, 136, 1)\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "================== Model called ========================\n",
            "input_size:  10\n",
            "batch_size:  565\n",
            "time_lenght:  136\n",
            "nb_filters:  53\n",
            "kernel_size:  9\n",
            "dropout_rate:  0.15\n",
            "dilations:  [1, 2, 4, 8, 17, 34, 68, 136]\n",
            "dropout_rate:  0.15\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 136, 10)]         0         \n",
            "                                                                 \n",
            " tcn (TCN)                   (None, 136, 53)           388808    \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 136, 1)           54        \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 388,862\n",
            "Trainable params: 387,166\n",
            "Non-trainable params: 1,696\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 19s 779ms/step - loss: 47.6433\n",
            "Epoch 2/2\n",
            "7/7 [==============================] - 3s 388ms/step - loss: 1.3908\n",
            "7/7 [==============================] - 1s 77ms/step\n",
            "7/7 [==============================] - 0s 77ms/step\n",
            "================== Model called ========================\n",
            "input_size:  10\n",
            "batch_size:  565\n",
            "time_lenght:  136\n",
            "nb_filters:  53\n",
            "kernel_size:  9\n",
            "dropout_rate:  0.15\n",
            "dilations:  [1, 2, 4, 8, 17, 34, 68, 136]\n",
            "dropout_rate:  0.15\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 136, 10)]         0         \n",
            "                                                                 \n",
            " tcn (TCN)                   (None, 136, 53)           388808    \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 136, 1)           54        \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 388,862\n",
            "Trainable params: 387,166\n",
            "Non-trainable params: 1,696\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 9s 388ms/step - loss: 44.7039\n",
            "Epoch 2/2\n",
            "7/7 [==============================] - 3s 390ms/step - loss: 1.7091\n",
            "7/7 [==============================] - 1s 76ms/step\n",
            "7/7 [==============================] - 0s 76ms/step\n",
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n",
            "================== Model called ========================\n",
            "input_size:  10\n",
            "batch_size:  565\n",
            "time_lenght:  136\n",
            "nb_filters:  67\n",
            "kernel_size:  9\n",
            "dropout_rate:  0.15\n",
            "dilations:  [1, 2, 4, 8, 17, 34, 68, 136]\n",
            "dropout_rate:  0.15\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 136, 10)]         0         \n",
            "                                                                 \n",
            " tcn (TCN)                   (None, 136, 67)           618142    \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 136, 1)           68        \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 618,210\n",
            "Trainable params: 616,066\n",
            "Non-trainable params: 2,144\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 18s 919ms/step - loss: 64.8710\n",
            "Epoch 2/2\n",
            "7/7 [==============================] - 3s 468ms/step - loss: 2.5717\n",
            "7/7 [==============================] - 1s 109ms/step\n",
            "7/7 [==============================] - 1s 96ms/step\n",
            "================== Model called ========================\n",
            "input_size:  10\n",
            "batch_size:  565\n",
            "time_lenght:  136\n",
            "nb_filters:  67\n",
            "kernel_size:  9\n",
            "dropout_rate:  0.15\n",
            "dilations:  [1, 2, 4, 8, 17, 34, 68, 136]\n",
            "dropout_rate:  0.15\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 136, 10)]         0         \n",
            "                                                                 \n",
            " tcn (TCN)                   (None, 136, 67)           618142    \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 136, 1)           68        \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 618,210\n",
            "Trainable params: 616,066\n",
            "Non-trainable params: 2,144\n",
            "_________________________________________________________________\n",
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 10s 462ms/step - loss: 61.6513\n",
            "Epoch 2/2\n",
            "7/7 [==============================] - 3s 465ms/step - loss: 2.2009\n",
            "7/7 [==============================] - 1s 96ms/step\n",
            "7/7 [==============================] - 1s 97ms/step\n",
            "<class 'dict'>\n",
            "{'mean_fit_time': array([17.32583845, 20.65430403]), 'std_fit_time': array([5.14557374, 6.76235747]), 'mean_score_time': array([1.41881144, 1.72049332]), 'std_score_time': array([0.00847042, 0.33814955]), 'param_kernel_size': masked_array(data=[9, 9],\n",
            "             mask=[False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'param_nb_filters': masked_array(data=[53, 67],\n",
            "             mask=[False, False],\n",
            "       fill_value='?',\n",
            "            dtype=object), 'params': [OrderedDict([('kernel_size', 9), ('nb_filters', 53)]), OrderedDict([('kernel_size', 9), ('nb_filters', 67)])], 'split0_test_score': array([-6.84332979e+10, -1.46141808e+08]), 'split1_test_score': array([-1.16807358e+10, -5.55390509e+10]), 'mean_test_score': array([-4.00570168e+10, -2.78425964e+10]), 'std_test_score': array([2.83762811e+10, 2.76964546e+10]), 'rank_test_score': array([2, 1], dtype=int32), 'split0_train_score': array([-6.84332979e+10, -1.46141808e+08]), 'split1_train_score': array([-1.16807358e+10, -5.55390509e+10]), 'mean_train_score': array([-4.00570168e+10, -2.78425964e+10]), 'std_train_score': array([2.83762811e+10, 2.76964546e+10]), 'rank_train_score': array([2, 1])}\n",
            "BayesSearchCV took 84.71 seconds for 2 candidates parameter settings. \n",
            "Best: -27842596368.217003 using OrderedDict([('kernel_size', 9), ('nb_filters', 67)])\n",
            "Rank: 0, R2: -27842596368.217 with OrderedDict([('kernel_size', 9), ('nb_filters', 67)])\n",
            "Rank: 1, R2: -40057016833.091 with OrderedDict([('kernel_size', 9), ('nb_filters', 53)])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Best 초모수 조합 출력**"
      ],
      "metadata": {
        "id": "anUcUN8sS3Rq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#=========================================================================\n",
        "# .. Second refit to evaluate best model use test period\n",
        "\n",
        "\n",
        "#-------------------------------------------------------------------------\n",
        "# .. Set model label\n",
        "\n",
        "# .. best model configuration for whole train set\n",
        "params = optimizer.best_params_\n",
        "print(type(params))\n",
        "print(params)"
      ],
      "metadata": {
        "id": "I2LjzM9ES4L3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "187f30ce-1662-4e47-d3e6-4f38240f7e50"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'collections.OrderedDict'>\n",
            "OrderedDict([('kernel_size', 9), ('nb_filters', 67)])\n"
          ]
        }
      ]
    }
  ]
}